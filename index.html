<!DOCTYPE html><!--Author: Pranav Rajpurkar 2016--><html><head><meta charset="utf-8"><title>Question Answering is Not a Trivial Activity </title><meta name="description" content="Question Answering is Not a Trivial Activity"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><meta property="og:image" content="/logo.png"><link rel="image_src" type="image/png" href="/qanta-leaderboard/logo.png"><link rel="shortcut icon" href="/qanta-leaderboard/favicon.ico" type="image/x-icon"><link rel="icon" href="/qanta-leaderboard/favicon.ico" type="image/x-icon"><link rel="stylesheet" href="/qanta-leaderboard/bower_components/bootstrap/dist/css/bootstrap.min.css"><link rel="stylesheet" href="/qanta-leaderboard/stylesheets/layout.css"><link rel="stylesheet" href="/qanta-leaderboard/stylesheets/index.css"><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/qanta-leaderboard/javascripts/analytics.js"></script></head><body><div class="navbar navbar-default navbar-fixed-top" id="topNavbar" role="navigation"><div class="container clearfix" id="navContainer"><div class="leftNav"><div class="brandDiv"><a class="navbar-brand" href="/qanta-leaderboard/">QANTA</a></div></div></div></div><div class="cover" id="topCover"><div class="container"><div class="row"><div class="col-md-12"><h1 id="appTitle">QANTA</h1><h3 id="appSubtitle">Question Answering is Not a Trivial Activity </h3><h2 id="appSubtitle">University of Maryland</h2></div></div></div></div><div class="cover" id="contentCover"><div class="container"><div class="row"><div class="col-md-5"><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>What is QANTA?</h2></div><p> </p>QANTA (<b>Q</b>uestion <b>A</b>answering is <b>N</b>ot a <b>T</b>rivial <b>A</b>ctivity) is a question answering dataset composed of questions from Quizbowl - a trivia game that is challenging for both humans and machines. Each question contains 4-5 pyramidally arranged clues: obscure ones at the beginning and obvious ones at the end.  Players of Quizbowl (humans and machines) compete to prove their superior mastery of knowledge by trying to answer using the least amount of information possible. More information on QANTA, including offline events, can be found at <a href="http://qanta.org">qanta.org</a>.<hr><p></p><span class="label label-default">New</span><b> On Dec.15th </b>University of Maryland will host a series of competitions including human vs. human, machine vs. human, and machine vs. machine. To find out more about the event and register (required for prizes), visit <a href="https://sites.google.com/view/qanta/dec-15-2018">qanta.org</a>.<div class="infoHeadline"><h2>Getting Started</h2></div><p></p>Download a copy of the dataset (distributed under the <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode">CC BY-SA 4.0 </a>license):<ul class="list-unstyled"><li><a class="btn actionBtn inverseBtn" href="https://www.google.com/url?q=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fpinafore-us-west-2%2Fqanta-jmlr-datasets%2Fqanta.train.2018.04.18.json&amp;sa=D">Training Set 2018.04.18 (136 MB)</a></li><li><a class="btn actionBtn inverseBtn" href="https://www.google.com/url?q=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fpinafore-us-west-2%2Fqanta-jmlr-datasets%2Fqanta.dev.2018.04.18.json&amp;sa=D">Dev Set 2018.04.18 (3 MB)</a></li></ul><p> </p>To help you get started and demonstrate our API requirements, we provide a baseline system. The repo below contains code to: download data, train model in a docker container, evaluate model in a way that is identical to the CodaLab evaluation. You should be able to reproduce the "Baseline" entry on the leaderboard. <ul class="list-unstyled"><li><a class="btn actionBtn inverseBtn" href="https://github.com/Pinafore/qanta-codalab">Baseline system</a></li></ul><p></p>Submissions are done through CodaLab and the models will be tested with the same evaluation script.<ul class="list-unstyled"><li><a class="btn actionBtn inverseBtn" href="http://codalab.qanta.org">CodaLab Submission Tutorial</a></li></ul><div class="infoHeadline"><h2>Have Questions?</h2></div><p> </p>Please send your questions to our <a href="https://groups.google.com/forum/#!forum/qanta">google group</a> or at <a href="mailto:pedro@cs.umd.edu">pedro@cs.umd.edu</a> and <a href="mailto:shifeng@cs.umd.edu">shifeng@cs.umd.edu</a>.<div class="infoHeadline"><h2>Acknowledgements</h2></div><p> </p>We thank the <a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD team </a>for allowing us to use their code and templates for generating this website.</div><div class="infoSubheadline"><a href="https://twitter.com/share" class="twitter-share-button" data-url="https://qanta.org" data-text="Question Answering is Not a Trivial Activity" data-via="boydgraber" data-size="large" data-hashtags="Quizbowl">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script></div></div></div><div class="col-md-7"><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>Leaderboard</h2></div><p></p>We evaluate each system with four metrics: accuracy at the end of the first sentence (first_acc) and at the end of the question (end_acc), and two new metrics: <a href="https://worksheets.codalab.org/worksheets/0xfb3d16165dd24f69bb1ba9420fca9212/">expected wins </a> with system buzzer (EW) and with optimal buzzer (EW_OPT). Ranking is decided by EW.<table class="table performanceTable"><tr><th>Rank</th><th>Model</th><th>first_acc</th><th>end_acc</th><th>EW</th><th>EW_OPT</th></tr><tr><td> <p>1</p><span class="date label label-default">Apr 04, 2019</span></td><td style="word-break:break-word;">TFIDF RNN Buzzer<p class="institution">CMSC 470 QANTA Handle Us </p></td><td>0.0530</td><td><b>0.469</b></td><td><b>0.201</b></td><td><b>0.513</b></td></tr><tr><td> <p>2</p><span class="date label label-default">Apr 04, 2019</span></td><td style="word-break:break-word;">Baseline<p class="institution">NLP CMSC470</p></td><td>0.0530</td><td><b>0.469</b></td><td>0.198</td><td><b>0.513</b></td></tr><tr><td> <p>3</p><span class="date label label-default">May 02, 2019</span></td><td style="word-break:break-word;">Naive IR Baseline<p class="institution">University of Maryland</p></td><td><b>0.0750</b></td><td>0.263</td><td>0.0450</td><td>0.462</td></tr><tr><td> <p>4</p><span class="date label label-default">Apr 26, 2019</span></td><td style="word-break:break-word;">Unnamed submission by amhonili<p class="institution"></p></td><td>0.0540</td><td>0.468</td><td>0.00300</td><td><b>0.513</b></td></tr><tr><td> <p>4</p><span class="date label label-default">Apr 19, 2019</span></td><td style="word-break:break-word;">Basic Baseline<p class="institution">CMSC470 Team CAT</p></td><td>0.0530</td><td><b>0.469</b></td><td>0.00300</td><td><b>0.513</b></td></tr><tr><td> <p>4</p><span class="date label label-default">Apr 18, 2019</span></td><td style="word-break:break-word;">James<p class="institution">CMSC470 + James/ UMD</p></td><td>0.0530</td><td><b>0.469</b></td><td>0.00300</td><td><b>0.513</b></td></tr><tr><td> <p>4</p><span class="date label label-default">Apr 23, 2019</span></td><td style="word-break:break-word;">Basic TFIDF Model<p class="institution">CMSC470 +Natural Language Partiers</p></td><td>0.0530</td><td><b>0.469</b></td><td>0.00300</td><td><b>0.513</b></td></tr><tr><td> <p>4</p><span class="date label label-default">Apr 24, 2019</span></td><td style="word-break:break-word;">Unnamed submission by amhonili<p class="institution"></p></td><td>0.0530</td><td><b>0.469</b></td><td>0.00300</td><td><b>0.513</b></td></tr><tr><td> <p>4</p><span class="date label label-default">Apr 29, 2019</span></td><td style="word-break:break-word;">Awesome System<p class="institution">CMSC723 Awesome Team</p><a class="link" href="https://arxiv.org/abs/something">https://arxiv.org/abs/something</a></td><td>0.0530</td><td><b>0.469</b></td><td>0.00300</td><td><b>0.513</b></td></tr><tr><td> <p>4</p><span class="date label label-default">Apr 25, 2019</span></td><td style="word-break:break-word;">Unnamed submission by xzientar<p class="institution"></p></td><td>0.0530</td><td><b>0.469</b></td><td>0.00300</td><td><b>0.513</b></td></tr><tr><td> <p>4</p><span class="date label label-default">Apr 05, 2019</span></td><td style="word-break:break-word;">Baseline<p class="institution">CMSC470 The Ensemblers/UMD</p></td><td>0.0530</td><td><b>0.469</b></td><td>0.00300</td><td><b>0.513</b></td></tr><tr><td> <p>5</p><span class="date label label-default">Apr 26, 2019</span></td><td style="word-break:break-word;">Baseline v1<p class="institution">CMSC470 Monkeys + Typewriters</p></td><td>0.0600</td><td>0.434</td><td>0.00</td><td><b>0.513</b></td></tr></table></div></div></div></div></div></div><script src="/qanta-leaderboard/bower_components/jquery/dist/jquery.min.js"></script><script src="/qanta-leaderboard/bower_components/bootstrap/dist/js/bootstrap.min.js"></script></body></html>