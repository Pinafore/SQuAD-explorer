extends layout

block title
  title Question Answering is Not a Trivial Activity 

block description
  meta(name='description', content='Question Answering is Not a Trivial Activity') 
block extralinks
  link(rel='stylesheet', href='/stylesheets/index.css')
  script(async defer src="https://buttons.github.io/buttons.js")

block extrascripts

mixin squad_2_model_display(group, is_test)
  table.table.performanceTable
    tr
      if is_test
        th Rank
      th Model
      th first_acc
      th end_acc
      th expected wins
    - var largest_sent1_acc = Math.max.apply(null, group.map(function (model) { return model.sent1_acc; }))
    - var largest_eoq_acc = Math.max.apply(null, group.map(function (model) { return model.eoq_acc; }))
    - var largest_curve = Math.max.apply(null, group.map(function (model) { return model.curve; }))
    each model in group
      tr
        if is_test
          td 
            p #{model.rank}
            span.date.label.label-default #{moment.unix(model.date).format('MMM DD, YYYY')}
        td(style="word-break:break-word;")
          | #{model.model_name}
          p.institution #{model.institution}
          if model.link
            a.link(href=model.link) #{model.link}
        td
          if model.sent1_acc == largest_sent1_acc
            b #{model.sent1_acc.toPrecision(5)}
          else
            | #{model.sent1_acc.toPrecision(5)}
        td
          if model.eoq_acc == largest_eoq_acc
            b #{model.eoq_acc.toPrecision(5)}
          else
            | #{model.eoq_acc.toPrecision(5)}
        td
          if model.curve == largest_curve
            b #{model.curve.toPrecision(5)}
          else
            | #{model.curve.toPrecision(5)}
block content
  .cover#contentCover
    .container
      .row
        .col-md-5
          .infoCard
            .infoBody
              .infoHeadline
                h2 What is QANTA?
              p 
              | QANTA (
              b Q
              |uestion 
              b A
              |answering is 
              b N
              |ot a 
              b T
              |rivial 
              b A
              |ctivity) is a question answering dataset composed of questions from Quizbowl - a trivia game that is challenging for both humans and machines. Each question contains 4-5 pyramidally arranged clues: obscure ones at the beginning and obvious ones at the end.  Players of Quizbowl (humans and machines) compete to prove their superior mastery of knowledge by trying to answer using the least amount of information possible. More information on QANTA, including offline events, can be found at 
              a(href="https://qanta.org") qanta.org
              | .
              hr
              p
                span.label.label-default New
                b  On Dec.15th 
                | University of Maryland will host a series of competitions including human vs. human, machine vs. human, and machine vs. machine. To find out more about the event and register (required for prizes), visit 
                a(href="https://sites.google.com/view/qanta/dec-15-2018") qanta.org
                | .
              .infoHeadline
                h2 Getting Started
              p
              | Download a copy of the dataset (distributed under the 
              a(href="https://creativecommons.org/licenses/by-sa/4.0/legalcode") CC BY-SA 4.0 
              | license):
              ul.list-unstyled
                li
                  a.btn.actionBtn.inverseBtn(href="https://www.google.com/url?q=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fpinafore-us-west-2%2Fqanta-jmlr-datasets%2Fqanta.train.2018.04.18.json&sa=D")
                    | Training Set 2018.04.18 (136 MB)
                li
                  a.btn.actionBtn.inverseBtn(href="https://www.google.com/url?q=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fpinafore-us-west-2%2Fqanta-jmlr-datasets%2Fqanta.dev.2018.04.18.json&sa=D")
                    | Dev Set 2018.04.18 (3 MB)
              p 
                | To help you get started and demonstrate our API requirements, we provide a baseline system. The repo below contains code to: download data, train model in a docker container, evaluate model in a way that is identical to the CodaLab evaluation. You should be able to reproduce the "Baseline" entry on the leaderboard. 
                ul.list-unstyled
                  li
                    a.btn.actionBtn.inverseBtn(href="https://github.com/Pinafore/qanta-codalab")
                      | Baseline system
                | Submissions are done through CodaLab and the models will be tested with the same evaluation script.
                ul.list-unstyled
                  li
                    a.btn.actionBtn.inverseBtn(href="http://codalab.qanta.org")
                      | CodaLab Submission Tutorial
              .infoHeadline
                h2 Have Questions?
              p 
                | Please send your questions to our 
                a(href="https://groups.google.com/forum/#!forum/qanta") google group
                |  or at 
                a(href="mailto:pedro@cs.umd.edu") pedro@cs.umd.edu
                |  and 
                a(href="mailto:shifeng@cs.umd.edu") shifeng@cs.umd.edu
                | .
              .infoHeadline
                h2 Acknowledgements
              p 
                | We thank the 
                a(href="https://rajpurkar.github.io/SQuAD-explorer/") SQuAD team 
                | for allowing us to use their code and templates for generating this website.
            .infoSubheadline
              include includes/tweet
        .col-md-7
          .infoCard
            .infoBody
              .infoHeadline
                h2 Leaderboard
              p
              | We evaluate each system with three metrics: accuracy at the end of the first sentence (first_acc) and at the end of the question (end_acc), and the 
              a(href="https://worksheets.codalab.org/worksheets/0xfb3d16165dd24f69bb1ba9420fca9212/") expected wins.
              +squad_2_model_display(test2, true)
