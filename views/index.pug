extends layout

block title
  title Question Answering is Not a Trivial Activity 

block description
  meta(name='description', content='Question Answering is Not a Trivial Activity') 
block extralinks
  link(rel='stylesheet', href='/stylesheets/index.css')
  script(async defer src="https://buttons.github.io/buttons.js")

block extrascripts

mixin squad_2_model_display(group, is_test)
  table.table.performanceTable
    tr
      if is_test
        th Rank
      th Model
      th sent1_acc
      th eoq_acc
      th curve
    - var largest_sent1_acc = Math.max.apply(null, group.map(function (model) { return model.sent1_acc; }))
    - var largest_eoq_acc = Math.max.apply(null, group.map(function (model) { return model.eoq_acc; }))
    - var largest_curve = Math.max.apply(null, group.map(function (model) { return model.curve; }))
    each model in group
      tr
        if is_test
          td 
            p #{model.rank}
            span.date.label.label-default #{moment.unix(model.date).format('MMM DD, YYYY')}
        td(style="word-break:break-word;")
          | #{model.model_name}
          p.institution #{model.institution}
          if model.link
            a.link(href=model.link) #{model.link}
        td
          if model.sent1_acc == largest_sent1_acc
            b #{model.sent1_acc.toPrecision(5)}
          else
            | #{model.sent1_acc.toPrecision(5)}
        td
          if model.eoq_acc == largest_eoq_acc
            b #{model.eoq_acc.toPrecision(5)}
          else
            | #{model.eoq_acc.toPrecision(5)}
        td
          if model.curve == largest_curve
            b #{model.curve.toPrecision(5)}
          else
            | #{model.curve.toPrecision(5)}
block content
  .cover#contentCover
    .container
      .row
        .col-md-5
          .infoCard
            .infoBody
              .infoHeadline
                h2 What is QANTA?
              p 
              | QANTA (
              b Q
              |uestion 
              b A
              |answering is 
              b N
              |ot a 
              b T
              |rivial 
              b A
              |ctivity) is a question answering dataset composed of questions from Quizbowl - a trivia game that is challenging for both humans and machines. Each question contains 4-5 pyramidally arranged clues: obscure ones at the beginning and obvious ones at the end.  Players of Quizbowl (humans and machines) compete to prove their superior mastery of knowledge by trying to answer using the least amount of information possible. More information on QANTA, including offline events, can be found at 
              a(href="https://qanta.org") qanta.org
              | .
              hr
              p
                span.label.label-default New
                b  On Dec.15th 
                | University of Maryland will host a series of competitions including human vs. human, machine vs. human, and machine vs. machine. For more information please see 
                a(href="https://sites.google.com/view/qanta/dec-15-2018") qanta.org
                | .
              .infoHeadline
                h2 Getting Started
              p
              | Download a copy of the dataset (distributed under the 
              a(href="https://creativecommons.org/licenses/by-sa/4.0/legalcode") CC BY-SA 4.0 
              | license):
              ul.list-unstyled
                li
                  a.btn.actionBtn.inverseBtn(href="https://www.google.com/url?q=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fpinafore-us-west-2%2Fqanta-jmlr-datasets%2Fqanta.train.2018.04.18.json&sa=D")
                    | Training Set 2018.04.18 (136 MB)
                li
                  a.btn.actionBtn.inverseBtn(href="https://www.google.com/url?q=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fpinafore-us-west-2%2Fqanta-jmlr-datasets%2Fqanta.dev.2018.04.18.json&sa=D")
                    | Dev Set 2018.04.18 (3 MB)
              p 
                | To help you get started and demonstrate our API requirements, we provide a baseline system that can be trained and evaluated with the official evaluation script in a docker container.
                ul.list-unstyled
                  li
                    a.btn.actionBtn.inverseBtn(href="https://github.com/Pinafore/qanta-codalab")
                      | Baseline system
                | Submissions are done through CodaLab and the models will be tested with the same evaluation script.
                ul.list-unstyled
                  li
                    a.btn.actionBtn.inverseBtn(href="http://codalab.qanta.org")
                      | CodaLab Submission Tutorial
              .infoHeadline
                h2 Have Questions?
              p 
                | Please send your questions to our 
                a(href="https://groups.google.com/forum/#!forum/qanta") google group
                |  or at 
                a(href="mailto:pedro@cs.umd.edu") pedro@cs.umd.edu
                |  and 
                a(href="mailto:shifeng@cs.umd.edu") shifeng@cs.umd.edu
                | .
              .infoHeadline
                h2 Acknowledgements
              p 
                | We thank the 
                a(href="https://rajpurkar.github.io/SQuAD-explorer/") SQuAD team 
                | for allowing us to use their code and templates for generating this website.
            .infoSubheadline
              include includes/tweet
        .col-md-7
          .infoCard
            .infoBody
              .infoHeadline
                h2 Leaderboard
              p
              | We evaluate each system with two accuracy metrics: at the end of the first sentence (sent1_acc), and at the end of the question (eoq_acc). We also use a third metric to take buzzing position into consideration (curve). 
              +squad_2_model_display(test2, true)
